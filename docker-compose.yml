# defaulted in orchestrator, bees need it to start properly if launched directly
x-metrics-env: &metrics-env
  MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_BASE_URL: http://pushgateway:9091
  MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_ENABLED: "true"
  MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_JOB: swarm1
  MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_PUSH_RATE: 10s
  MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_SHUTDOWN_OPERATION: DELETE
  MANAGEMENT_METRICS_TAGS_SWARM: swarm1

services:
#--------------------------------------
# Off the Shelf Services
#--------------------------------------
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    command:
      [
        "sh", "-c",
        "rabbitmq-plugins enable --offline rabbitmq_web_stomp && rabbitmq-server"
      ]
    environment: {}
    # exposed so that e2e tests can run outside of the docker network
    ports:
      - "5672:5672"
      - "15672:15672"
      - "15674:15674"
    volumes:
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD-SHELL", "nc -z 127.0.0.1 5672"]
      interval: 5s
      timeout: 10s
      retries: 24
      start_period: 30s

  redis:
    image: redis:7-alpine
    command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      REDIS_HOSTS: local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:8081"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  prometheus:
    image: prom/prometheus:latest
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.external-url=http://localhost:8088/prometheus/
      - --web.route-prefix=/prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    # ports:
    #   - "9090:9090"

  grafana:
    image: grafana/grafana
    environment:
      GF_SECURITY_ADMIN_USER: pockethive
      GF_SECURITY_ADMIN_PASSWORD: pockethive
    volumes:
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini:ro
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    # Expose Grafana via the UI reverse-proxy at http://localhost:8088/grafana
    depends_on:
      - prometheus
      - loki

  loki:
    # Pin Loki: newer tags dropped /bin/sh which breaks our shell-based entrypoint below.
    image: grafana/loki:2.9.1
    entrypoint:
      - /bin/sh
      - -c
      - |
          set -e
          chown -R 10001:10001 /var/lib/loki
          exec su -s /bin/sh loki -c "/usr/bin/loki -config.file=/etc/loki/config.yml"
    user: "0"
    # ports:
    #   - "3100:3100"
    volumes:
      - ./loki/config.yml:/etc/loki/config.yml:ro
      - loki-data:/var/lib/loki

  pushgateway:
    image: prom/pushgateway:latest
    # expose:
    #   - "9091"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://127.0.0.1:9091/-/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  wiremock:
    image: holomekc/wiremock-gui:latest
    command:
      [
        "--verbose",                          # useful logs for debugging
        "--disable-banner",                   # cleaner output
        "--async-response-enabled",           # enable async responses (better throughput)
        "--global-response-templating",       # allows templating across all stubs
        "--record-mappings",                  # auto-record mappings (if needed for tests)
        # "--no-request-journal",             # disable detailed journaling for perf (optional, see note below)
        "--max-request-journal-entries=1000", # avoid memory blowup, keep it reasonable
        "--enable-stub-cors",                # allow cross-origin access
      ]
    environment:
      LANG: en_US.UTF-8
      JAVA_OPTS: >-
        -XX:+UseG1GC
        -XX:+ParallelRefProcEnabled
        -XX:MaxRAMPercentage=75
        -XX:+HeapDumpOnOutOfMemoryError
        -Djava.net.preferIPv4Stack=true
        -Djava.awt.headless=true
    ports:
      - "8080:8080"
    volumes:
      - ./wiremock/mappings:/home/wiremock/mappings
      - ./wiremock/__files:/home/wiremock/__files

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: pockethive
      POSTGRES_USER: pockethive
      POSTGRES_PASSWORD: pockethive
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pockethive -d pockethive -h 127.0.0.1 -p 5432"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 10s

  tcp-mock-server:
    image: ${DOCKER_REGISTRY:-}tcp-mock-server:${POCKETHIVE_VERSION:-latest}
    ports:
      - "8083:8080"  # Web UI port
      - "9090:9090"  # TCP server port
    environment:
      SERVER_PORT: 8080
      TCP_MOCK_PORT: 9090
      TCP_MOCK_NODE_ID: "tcp-mock-1"
      TCP_MOCK_DASHBOARD_ENABLED: "true"
      TCP_MOCK_DASHBOARD_USERNAME: "admin"
      TCP_MOCK_DASHBOARD_PASSWORD: "admin"
      TCP_MOCK_SSL_ENABLED: "false"
      TCP_MOCK_VALIDATION_ENABLED: "true"
      TCP_MOCK_FILTERING_ENABLED: "true"
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: "health,info,metrics,prometheus"
    volumes:
      - ./tcp-mock-server/mappings:/app/mappings:ro
      - ./tcp-mock-server/__files:/app/__files:ro
      - tcp-mock-data:/app/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      - prometheus

  # promtail:
  #   # disabled: logs are shipped via RabbitMQ and aggregated to Loki
  #   image: grafana/promtail:2.9.1
  #   command: -config.file=/etc/promtail/config.yml
  #   ports:
  #     - "9080:9080"
  #   volumes:
  #     - ./promtail/config.yml:/etc/promtail/config.yml:ro
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #   depends_on:
  #     - loki

#--------------------------------------
# PocketHive Services
#--------------------------------------

  ui:
    image: ${DOCKER_REGISTRY:-}ui:${POCKETHIVE_VERSION:-latest}
    depends_on:
      scenario-manager:
        condition: service_healthy
    ports:
      - "8088:8088"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:8088/healthz | grep -q ok"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 5s

  ui-v2:
    image: ${DOCKER_REGISTRY:-}ui-v2:${POCKETHIVE_VERSION:-latest}
    depends_on:
      ui:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:8089/healthz | grep -q ok"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 5s

  log-aggregator:
    image: ${DOCKER_REGISTRY:-}log-aggregator:${POCKETHIVE_VERSION:-latest}
    environment:
      <<: *metrics-env
      RABBITMQ_HOST: rabbitmq
      POCKETHIVE_LOGS_EXCHANGE: ph.logs
      POCKETHIVE_LOGS_QUEUE: ph.logs.agg
      POCKETHIVE_LOKI_URL: http://loki:3100
      MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_GROUPING_KEY_INSTANCE: log-aggregator
      MANAGEMENT_METRICS_TAGS_INSTANCE: log-aggregator
    depends_on:
      rabbitmq:
        condition: service_started
      loki:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8080/actuator/health | grep -q UP"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 30s
    ports:
      - "1080:8080"

  orchestrator:
    image: ${DOCKER_REGISTRY:-}orchestrator:${POCKETHIVE_VERSION:-latest}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${POCKETHIVE_SCENARIOS_RUNTIME_ROOT:-/opt/pockethive/scenarios-runtime}:/app/scenarios-runtime
# all defaulted in application.yml, uncomment to override here
    environment:
      POCKETHIVE_SCENARIOS_RUNTIME_ROOT: /opt/pockethive/scenarios-runtime
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/pockethive
      SPRING_DATASOURCE_USERNAME: pockethive
      SPRING_DATASOURCE_PASSWORD: pockethive
      POCKETHIVE_JOURNAL_SINK: postgres
      POCKETHIVE_CONTROL_PLANE_ORCHESTRATOR_RABBIT_LOGGING_ENABLED: "true"
      POCKETHIVE_CONTROL_PLANE_ORCHESTRATOR_RABBIT_LOGS_EXCHANGE: ph.logs
#      <<: *metrics-env
#      POCKETHIVE_CONTROL_PLANE_EXCHANGE: ph.control
#      POCKETHIVE_CONTROL_PLANE_CONTROL_QUEUE: ph.control
    depends_on:
      rabbitmq:
        condition: service_healthy
      log-aggregator:
        condition: service_healthy
      postgres:
        condition: service_healthy


  scenario-manager:
    image: ${DOCKER_REGISTRY:-}scenario-manager:${POCKETHIVE_VERSION:-latest}
    environment:
      <<: *metrics-env
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_LOGGING_ENABLED: "true"
      POCKETHIVE_LOGS_EXCHANGE: ph.logs
      POCKETHIVE_CONTROL_PLANE_SWARM_ID: hive
      POCKETHIVE_CONTROL_PLANE_INSTANCE_ID: scenario-manager
      POCKETHIVE_CONTROL_PLANE_MANAGER_ROLE: scenario-manager
      POCKETHIVE_LOGS_QUEUE: ph.logs.agg
      MANAGEMENT_PROMETHEUS_METRICS_EXPORT_PUSHGATEWAY_GROUPING_KEY_INSTANCE: scenario-manager
      MANAGEMENT_METRICS_TAGS_INSTANCE: scenario-manager
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:8080/actuator/health | grep -q UP"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 30s
    ports:
      - "1081:8080"
    volumes:
      - ./scenarios:/app/scenarios
      - ${POCKETHIVE_SCENARIOS_RUNTIME_ROOT:-/opt/pockethive/scenarios-runtime}:/app/scenarios-runtime
    depends_on:
      log-aggregator:
        condition: service_healthy

#------------------------------------------
# Volumes
#------------------------------------------
volumes:
  rabbitmq-data:
  prometheus-data:
  grafana-data:
  loki-data:
  redis-data:
  postgres-data:
  tcp-mock-data:

networks:
  default:
    ipam:
      config:
        - subnet: 172.20.0.0/16
